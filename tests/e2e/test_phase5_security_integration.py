import pytest
import asyncio
from fastapi.testclient import TestClient
from typing import Dict, Any
import json
import time
from datetime import datetime, timedelta

class TestPhase5SecurityIntegration:
    """End-to-end tests for Phase 5 Security & Governance features"""
    
    def setup_method(self):
        """Setup test client and test data"""
        # This would be initialized with your FastAPI app
        # self.client = TestClient(app)
        self.test_project_id = "test-project-123"
        self.test_user_id = "test-user-456"
        self.test_admin_id = "admin-user-789"
        
    def test_rls_enforcement_workflow(self):
        """Test Row Level Security enforcement across all operations"""
        # Test user access to their own project
        response = self.client.get(f"/api/projects/{self.test_project_id}")
        assert response.status_code == 200
        
        # Test user denied access to other project
        response = self.client.get("/api/projects/other-project-999")
        assert response.status_code == 403
        
        # Test AI-generated content tracking
        response = self.client.post(
            f"/api/projects/{self.test_project_id}/story/arcs",
            json={
                "title": "AI Generated Story",
                "description": "Generated by AI",
                "isAIGenerated": True
            },
            headers={"X-AI-Generated": "true"}
        )
        assert response.status_code == 201
        
        # Verify audit log entry for AI generation
        audit_response = self.client.get(f"/api/security/projects/{self.test_project_id}/audit-trail")
        assert audit_response.status_code == 200
        audit_logs = audit_response.json()
        assert any(log["isAIGenerated"] for log in audit_logs)
        
    def test_rbac_permission_checks(self):
        """Test Role-Based Access Control for different user roles"""
        # Test owner permissions
        owner_response = self.client.post(
            f"/api/projects/{self.test_project_id}/story/arcs",
            json={"title": "Owner Story", "description": "Created by owner"}
        )
        assert owner_response.status_code == 201
        
        # Test editor permissions
        editor_response = self.client.put(
            f"/api/projects/{self.test_project_id}/story/arcs/{owner_response.json()['id']}",
            json={"title": "Edited Story", "description": "Edited by editor"}
        )
        assert editor_response.status_code == 200
        
        # Test viewer permissions (should be denied for write operations)
        viewer_response = self.client.delete(
            f"/api/projects/{self.test_project_id}/story/arcs/{owner_response.json()['id']}"
        )
        assert viewer_response.status_code == 403
        
    def test_audit_logging_ai_vs_human(self):
        """Test audit logging for AI vs human edits"""
        # Create human-generated content
        human_response = self.client.post(
            f"/api/projects/{self.test_project_id}/dialogues",
            json={
                "content": "Human written dialogue",
                "characterId": "char-1",
                "isAIGenerated": False
            }
        )
        assert human_response.status_code == 201
        
        # Create AI-generated content
        ai_response = self.client.post(
            f"/api/projects/{self.test_project_id}/dialogues",
            json={
                "content": "AI generated dialogue",
                "characterId": "char-1",
                "isAIGenerated": True
            },
            headers={"X-AI-Generated": "true"}
        )
        assert ai_response.status_code == 201
        
        # Get edit statistics
        stats_response = self.client.get(
            f"/api/security/projects/{self.test_project_id}/edit-statistics"
        )
        assert stats_response.status_code == 200
        stats = stats_response.json()
        
        assert stats["totalEdits"] >= 2
        assert stats["aiEdits"] >= 1
        assert stats["humanEdits"] >= 1
        assert stats["aiEditPercentage"] > 0
        
    def test_signed_urls_generation(self):
        """Test signed URL generation for secure file access"""
        # Generate upload URL
        upload_response = self.client.post(
            f"/api/security/projects/{self.test_project_id}/upload-url",
            json={
                "fileName": "test-file.txt",
                "contentType": "text/plain",
                "expiresIn": 3600
            }
        )
        assert upload_response.status_code == 200
        upload_data = upload_response.json()
        assert "uploadUrl" in upload_data
        assert "fileKey" in upload_data
        assert "expiresAt" in upload_data
        
        # Generate download URL
        download_response = self.client.post(
            f"/api/security/projects/{self.test_project_id}/download-url",
            json={
                "fileKey": upload_data["fileKey"],
                "expiresIn": 3600
            }
        )
        assert download_response.status_code == 200
        download_data = download_response.json()
        assert "downloadUrl" in download_data
        assert "expiresAt" in download_data
        
        # Test URL expiration
        expired_response = self.client.post(
            f"/api/security/projects/{self.test_project_id}/upload-url",
            json={
                "fileName": "expired-file.txt",
                "expiresIn": 1  # 1 second
            }
        )
        assert expired_response.status_code == 200
        
        # Wait for expiration
        time.sleep(2)
        
        # URL should be expired (this would be tested with actual S3 integration)
        
    def test_per_project_encryption(self):
        """Test per-project encryption key generation and data encryption"""
        # Generate encryption key
        key_response = self.client.post(
            f"/api/security/projects/{self.test_project_id}/encryption-key"
        )
        assert key_response.status_code == 200
        encryption_key = key_response.json()
        assert "keyId" in encryption_key
        assert "encryptedKey" in encryption_key
        assert "algorithm" in encryption_key
        
        # Encrypt data
        test_data = "Sensitive project data that needs encryption"
        encrypt_response = self.client.post(
            f"/api/security/projects/{self.test_project_id}/encrypt-data",
            json={
                "data": test_data,
                "encryptionKey": encryption_key
            }
        )
        assert encrypt_response.status_code == 200
        encrypted_data = encrypt_response.json()
        assert "encryptedData" in encrypted_data
        assert "iv" in encrypted_data
        assert "tag" in encrypted_data
        
        # Decrypt data
        decrypt_response = self.client.post(
            f"/api/security/projects/{self.test_project_id}/decrypt-data",
            json={
                "encryptedData": encrypted_data["encryptedData"],
                "iv": encrypted_data["iv"],
                "tag": encrypted_data["tag"],
                "encryptionKey": encryption_key
            }
        )
        assert decrypt_response.status_code == 200
        decrypted_data = decrypt_response.json()
        assert decrypted_data["data"] == test_data
        
    def test_data_export_gdpr_compliance(self):
        """Test GDPR-compliant data export functionality"""
        # Export project data in JSON format
        export_response = self.client.post(
            f"/api/security/projects/{self.test_project_id}/export",
            json={
                "format": "json",
                "includeAuditLogs": True,
                "includeDeleted": False,
                "encryptionKey": "optional-encryption"
            }
        )
        assert export_response.status_code == 200
        export_data = export_response.json()
        assert "exportId" in export_data
        assert "downloadUrl" in export_data
        assert "expiresAt" in export_data
        assert "fileSize" in export_data
        assert "recordCount" in export_data
        assert "checksum" in export_data
        
        # Export in CSV format
        csv_export_response = self.client.post(
            f"/api/security/projects/{self.test_project_id}/export",
            json={
                "format": "csv",
                "includeAuditLogs": False,
                "includeDeleted": False
            }
        )
        assert csv_export_response.status_code == 200
        
        # Export in XML format
        xml_export_response = self.client.post(
            f"/api/security/projects/{self.test_project_id}/export",
            json={
                "format": "xml",
                "includeAuditLogs": True,
                "includeDeleted": True
            }
        )
        assert xml_export_response.status_code == 200
        
    def test_data_deletion_gdpr_compliance(self):
        """Test GDPR-compliant data deletion functionality"""
        # Soft delete project data
        soft_delete_response = self.client.delete(
            f"/api/security/projects/{self.test_project_id}/data",
            json={
                "softDelete": True,
                "deleteAuditLogs": False,
                "deleteExports": False
            }
        )
        assert soft_delete_response.status_code == 200
        soft_delete_data = soft_delete_response.json()
        assert "deletionId" in soft_delete_data
        assert "deletedRecords" in soft_delete_data
        assert "deletedAt" in soft_delete_data
        assert "auditLogId" in soft_delete_data
        
        # Hard delete project data
        hard_delete_response = self.client.delete(
            f"/api/security/projects/{self.test_project_id}/data",
            json={
                "softDelete": False,
                "deleteAuditLogs": True,
                "deleteExports": True
            }
        )
        assert hard_delete_response.status_code == 200
        hard_delete_data = hard_delete_response.json()
        assert "deletionId" in hard_delete_data
        
    def test_content_policy_configuration(self):
        """Test content policy configuration and enforcement"""
        # Set content policy
        policy_response = self.client.post(
            f"/api/content-policy/projects/{self.test_project_id}",
            json={
                "ageRating": "PG-13",
                "themes": ["fantasy", "adventure"],
                "tone": "family",
                "violenceLevel": "mild",
                "languageLevel": "clean",
                "sexualContent": "none",
                "drugContent": "none",
                "politicalContent": "none",
                "customFilters": ["banned-word-1", "banned-word-2"],
                "autoReviewThreshold": 3
            }
        )
        assert policy_response.status_code == 200
        policy_data = policy_response.json()
        assert policy_data["ageRating"] == "PG-13"
        assert "fantasy" in policy_data["themes"]
        
        # Check content against policy
        check_response = self.client.post(
            f"/api/content-policy/projects/{self.test_project_id}/check",
            json={
                "content": "This is a family-friendly fantasy adventure story.",
                "contentType": "story"
            }
        )
        assert check_response.status_code == 200
        check_data = check_response.json()
        assert check_data["passed"] == True
        assert len(check_data["violations"]) == 0
        
        # Check content that violates policy
        violation_response = self.client.post(
            f"/api/content-policy/projects/{self.test_project_id}/check",
            json={
                "content": "This story contains explicit violence and strong language.",
                "contentType": "story"
            }
        )
        assert violation_response.status_code == 200
        violation_data = violation_response.json()
        assert violation_data["passed"] == False
        assert len(violation_data["violations"]) > 0
        assert violation_data["requiresReview"] == True
        
    def test_content_review_queue(self):
        """Test content review queue functionality"""
        # Submit content for review
        submit_response = self.client.post(
            f"/api/content-policy/projects/{self.test_project_id}/submit-review",
            json={
                "contentId": "content-123",
                "contentType": "dialogue",
                "content": "This dialogue contains questionable content.",
                "isAIGenerated": True
            }
        )
        assert submit_response.status_code == 200
        submit_data = submit_response.json()
        assert "reviewId" in submit_data
        assert submit_data["status"] == "pending"
        
        # Get review queue
        queue_response = self.client.get(
            f"/api/content-policy/projects/{self.test_project_id}/review-queue"
        )
        assert queue_response.status_code == 200
        queue_data = queue_response.json()
        assert len(queue_data) >= 1
        assert any(review["id"] == submit_data["reviewId"] for review in queue_data)
        
        # Review content (approve)
        approve_response = self.client.post(
            f"/api/content-policy/reviews/{submit_data['reviewId']}",
            json={
                "reviewerId": self.test_admin_id,
                "status": "approved",
                "reviewNotes": "Content is acceptable after minor edits."
            }
        )
        assert approve_response.status_code == 200
        approve_data = approve_response.json()
        assert approve_data["status"] == "approved"
        assert approve_data["reviewerId"] == self.test_admin_id
        
        # Submit content for review that gets rejected
        reject_submit_response = self.client.post(
            f"/api/content-policy/projects/{self.test_project_id}/submit-review",
            json={
                "contentId": "content-456",
                "contentType": "story",
                "content": "This story contains explicit content that violates policy.",
                "isAIGenerated": False
            }
        )
        assert reject_submit_response.status_code == 200
        
        # Review content (reject)
        reject_response = self.client.post(
            f"/api/content-policy/reviews/{reject_submit_response.json()['reviewId']}",
            json={
                "reviewerId": self.test_admin_id,
                "status": "rejected",
                "reviewNotes": "Content violates multiple policy guidelines."
            }
        )
        assert reject_response.status_code == 200
        reject_data = reject_response.json()
        assert reject_data["status"] == "rejected"
        
    def test_url_revocation(self):
        """Test signed URL revocation functionality"""
        # Generate multiple URLs
        url1_response = self.client.post(
            f"/api/security/projects/{self.test_project_id}/upload-url",
            json={"fileName": "file1.txt"}
        )
        url2_response = self.client.post(
            f"/api/security/projects/{self.test_project_id}/upload-url",
            json={"fileName": "file2.txt"}
        )
        assert url1_response.status_code == 200
        assert url2_response.status_code == 200
        
        # Revoke all URLs for project
        revoke_response = self.client.post(
            f"/api/security/projects/{self.test_project_id}/revoke-urls"
        )
        assert revoke_response.status_code == 200
        revoke_data = revoke_response.json()
        assert "message" in revoke_data
        
        # Verify URLs are revoked (this would be tested with actual S3 integration)
        
    def test_performance_under_security_load(self):
        """Test system performance under security enforcement load"""
        import concurrent.futures
        
        def make_concurrent_requests():
            """Make concurrent requests to test RLS/RBAC performance"""
            responses = []
            for i in range(10):
                response = self.client.get(f"/api/projects/{self.test_project_id}")
                responses.append(response.status_code)
            return responses
        
        # Test concurrent access
        with concurrent.futures.ThreadPoolExecutor(max_workers=5) as executor:
            futures = [executor.submit(make_concurrent_requests) for _ in range(5)]
            results = [future.result() for future in concurrent.futures.as_completed(futures)]
        
        # All requests should succeed
        for result in results:
            assert all(status == 200 for status in result)
        
        # Test audit logging performance
        start_time = time.time()
        for i in range(100):
            self.client.post(
                f"/api/projects/{self.test_project_id}/story/arcs",
                json={
                    "title": f"Performance Test Story {i}",
                    "description": "Testing audit logging performance",
                    "isAIGenerated": i % 2 == 0  # Alternate between AI and human
                }
            )
        end_time = time.time()
        
        # Should complete within reasonable time (adjust threshold as needed)
        assert end_time - start_time < 30  # 30 seconds for 100 requests
        
    def test_security_error_handling(self):
        """Test security error handling and edge cases"""
        # Test invalid project access
        invalid_response = self.client.get("/api/projects/invalid-project-id")
        assert invalid_response.status_code == 403
        
        # Test expired tokens
        expired_response = self.client.get(
            f"/api/projects/{self.test_project_id}",
            headers={"Authorization": "Bearer expired-token"}
        )
        assert expired_response.status_code == 401
        
        # Test malformed encryption data
        malformed_encrypt_response = self.client.post(
            f"/api/security/projects/{self.test_project_id}/encrypt-data",
            json={
                "data": "test data",
                "encryptionKey": "invalid-key-format"
            }
        )
        assert malformed_encrypt_response.status_code == 400
        
        # Test content policy with invalid configuration
        invalid_policy_response = self.client.post(
            f"/api/content-policy/projects/{self.test_project_id}",
            json={
                "ageRating": "INVALID-RATING",
                "themes": ["invalid-theme"],
                "violenceLevel": "invalid-level"
            }
        )
        assert invalid_policy_response.status_code == 400

# Test execution
if __name__ == "__main__":
    pytest.main([__file__, "-v"])
